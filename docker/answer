#!/usr/bin/python3 -W ignore::DeprecationWarning
# -*- coding:utf8 -*-
import sys
import spacy
import re
import codecs
from transformers import BertForQuestionAnswering, AutoTokenizer, pipeline
import os

if __name__ == "__main__":
    input_file = sys.argv[1]
    question_file = sys.argv[2]

    model = BertForQuestionAnswering.from_pretrained('deepset/bert-base-cased-squad2')
    tokenizer = AutoTokenizer.from_pretrained('deepset/bert-base-cased-squad2')
    classifier = pipeline("zero-shot-classification", model="joeddav/xlm-roberta-large-xnli")

    class_labels = ['chinese_dynasties', 'constellations', 'indian_states', 'languages', 'pokemon_characters']
    text_labels = {
        'chinese_dynasties': ['Chen_dynasty', 'Han_dynasty', 'Jin_dynasty_(266–420)', 'Liang_dynasty', 'Liu_Song_dynasty', 'Northern_Wei', 'Shang_dynasty', 'Tang_dynasty', 'Sui_dynasty', 'Xia_dynasty', 'Xin_dynasty', 'Zhou_dynasty'],
        'constellations': ['aquarius_constellation', 'aries_constellation', 'cancer_constellation', 'capricorn_constellation', 'gemini_constellation', 'leo_constellation', 'libra_constellation', 'pisces_constellation', 'sagittarius_constellation', 'scorpio_constellation', 'taurus_constellation', 'virgo_constellation'],
        'indian_states': ['Andhra_Pradesh', 'Gujarat','Karnataka', 'Kerala', 'Madhya_Pradesh', 'Maharashtra', 'Meghalaya','Punjab', 'Rajasthan', 'Tamil_Nadu', 'Uttar_Pradesh', 'West_Bengal'],
        'languages': ['Arabic_language', 'Bengali_language', 'English_language', 'French_language', 'German_language', 'Hindi_language', 'Indonesian_language', 'Mandarin_language', 'Portuguese_language', 'Russian_language', 'Spanish_language', 'Urdu_language'],
        'pokemon_characters': ['bulbasaur_pokemon', 'charizard_pokemon', 'charmander_pokemon', 'eevee_pokemon', 'jigglypuff_pokemon','magikarp_pokemon', 'mewtwo_pokemon', 'pikachu_pokemon', 'psyduck_pokemon', 'snorlax_pokemon', 'squirtle_pokemon', 'vulpix_pokemon']
    }

    with open(question_file, 'r') as f:
        count = 0
        for line in f:
            questions = [line]

            results = classifier(questions, class_labels)
            text = classifier(questions, text_labels[results[0]['labels'][0]])
            
            with codecs.open(os.path.join(input_file, results[0]['labels'][0], text[0]['labels'][0]+'.txt'), 'r', 'utf-8') as f:
                lines = f.readlines()
                context = ''
                for line in lines:
                    line = line.strip()
                    line = re.sub("[=+,#/\?:^@*\"※~ㆍ!』‘|\(\)\[\]`\'…》\”\“\’·]","", line)
                    line = re.sub(r"[一-龥]"," ", line)            
                    if line == '':
                        continue
                    context += line + ' '
             
            tokenizer.encode(questions[0], truncation = True, padding = True)
            tokenizer.encode('[CLS]')
            nlp = pipeline('question-answering', model=model, tokenizer = tokenizer)
            final = nlp({
                'question': questions[0],
                'context': context
            })

            count += 1
            print('A'+str(count) + ': ' + final['answer'])
            